# üìä ELK Stack - Monitoring & Logging - PM AI MVP

**Data de Cria√ß√£o:** 2 de Setembro de 2025  
**√öltima Atualiza√ß√£o:** 2 de Setembro de 2025  
**Status:** ‚úÖ **Fase 3: Sistema de Produ√ß√£o e Deploy - Monitoring & Logging CONCLU√çDA**  
**Respons√°vel:** Equipe de Desenvolvimento PM AI MVP

---

## üéØ **Vis√£o Geral**

Este documento descreve a implementa√ß√£o completa do ELK Stack (Elasticsearch, Logstash, Kibana) para monitoramento e logging avan√ßado do PM AI MVP, incluindo alertas autom√°ticos e dashboards personalizados.

---

## üèóÔ∏è **Arquitetura do ELK Stack**

### **Componentes Implementados:**

1. **Elasticsearch 8.11.0**
   - Armazenamento e indexa√ß√£o de logs
   - Busca e an√°lise de dados
   - API REST para consultas

2. **Logstash 8.11.0**
   - Processamento e transforma√ß√£o de logs
   - Parsing de diferentes formatos
   - Enriquecimento de dados

3. **Kibana 8.11.0**
   - Interface de visualiza√ß√£o
   - Dashboards personalizados
   - An√°lise de dados em tempo real

4. **Filebeat 8.11.0**
   - Coleta de logs de arquivos
   - Monitoramento de containers Docker
   - Envio para Logstash

5. **Metricbeat 8.11.0**
   - Coleta de m√©tricas do sistema
   - Monitoramento de servi√ßos
   - M√©tricas de performance

6. **APM Server 8.11.0**
   - Application Performance Monitoring
   - Rastreamento de transa√ß√µes
   - An√°lise de performance

---

## üìã **Configura√ß√µes Implementadas**

### **1. Elasticsearch** (`logging/elasticsearch/elasticsearch.yml`)

**Caracter√≠sticas:**
- ‚úÖ Cluster single-node para desenvolvimento
- ‚úÖ Seguran√ßa desabilitada (modo desenvolvimento)
- ‚úÖ Index Lifecycle Management (ILM)
- ‚úÖ Machine Learning habilitado
- ‚úÖ Watcher para alertas
- ‚úÖ Performance otimizada

**Configura√ß√µes de Performance:**
```yaml
indices.memory.index_buffer_size: 20%
indices.queries.cache.size: 10%
thread_pool.write.queue_size: 1000
```

### **2. Logstash** (`logging/logstash/`)

**Pipeline Principal** (`pipeline/main.conf`):
- ‚úÖ Inputs: Beats, TCP, HTTP, Docker
- ‚úÖ Parsing: JSON, Grok patterns
- ‚úÖ Filtros: Data parsing, GeoIP, User Agent
- ‚úÖ Output: Elasticsearch com templates

**Configura√ß√µes** (`config/logstash.yml`):
- ‚úÖ Workers: 2
- ‚úÖ Batch size: 1000
- ‚úÖ Queue persistida
- ‚úÖ Dead letter queue

### **3. Kibana** (`logging/kibana/kibana.yml`)

**Caracter√≠sticas:**
- ‚úÖ Interface otimizada
- ‚úÖ Dashboards personalizados
- ‚úÖ Index patterns autom√°ticos
- ‚úÖ Time picker configurado
- ‚úÖ Plugins habilitados

### **4. Filebeat** (`logging/filebeat/filebeat.yml`)

**Inputs Configurados:**
- ‚úÖ Docker containers
- ‚úÖ Application logs
- ‚úÖ Nginx logs
- ‚úÖ PostgreSQL logs
- ‚úÖ Redis logs

### **5. Metricbeat** (`logging/metricbeat/metricbeat.yml`)

**M√≥dulos Ativos:**
- ‚úÖ System metrics
- ‚úÖ Docker metrics
- ‚úÖ Elasticsearch metrics
- ‚úÖ Logstash metrics
- ‚úÖ Kibana metrics
- ‚úÖ PostgreSQL metrics
- ‚úÖ Redis metrics
- ‚úÖ Nginx metrics

### **6. APM Server** (`logging/apm-server/apm-server.yml`)

**Funcionalidades:**
- ‚úÖ Application monitoring
- ‚úÖ Performance tracking
- ‚úÖ Error tracking
- ‚úÖ RUM (Real User Monitoring)
- ‚úÖ Jaeger integration
- ‚úÖ OTLP support

---

## üìä **Dashboards e Visualiza√ß√µes**

### **Dashboard Principal** (`kibana/dashboards/pm-ai-dashboard.json`)

**Visualiza√ß√µes Inclu√≠das:**

1. **Application Logs Overview**
   - Histograma de logs por n√≠vel
   - Distribui√ß√£o temporal
   - Filtros por servi√ßo

2. **Error Rate Trends**
   - Tend√™ncia de erros ao longo do tempo
   - Alertas autom√°ticos
   - An√°lise de padr√µes

3. **Response Time Distribution**
   - Distribui√ß√£o de tempos de resposta
   - Percentis de performance
   - Identifica√ß√£o de gargalos

4. **Service Health Status**
   - Status de sa√∫de dos servi√ßos
   - Disponibilidade em tempo real
   - M√©tricas de uptime

### **Index Patterns:**
- `pm-ai-logs-*` - Logs da aplica√ß√£o
- `pm-ai-metrics-*` - M√©tricas do sistema
- `apm-*` - Dados de APM

---

## üö® **Sistema de Alertas**

### **Watcher Alerts** (`elasticsearch/watcher-alerts.json`)

**Alertas Implementados:**

1. **Error Rate Alert**
   - **Trigger:** A cada 1 minuto
   - **Condi√ß√£o:** > 10 erros em 5 minutos
   - **A√ß√£o:** Webhook notification

2. **Response Time Alert**
   - **Trigger:** A cada 2 minutos
   - **Condi√ß√£o:** > 2000ms m√©dia
   - **A√ß√£o:** Webhook notification

3. **Service Down Alert**
   - **Trigger:** A cada 5 minutos
   - **Condi√ß√£o:** < 4 servi√ßos reportando
   - **A√ß√£o:** Webhook notification

4. **Security Alert**
   - **Trigger:** A cada 1 minuto
   - **Condi√ß√£o:** > 5 eventos de seguran√ßa
   - **A√ß√£o:** Webhook notification

### **Configura√ß√£o de Webhooks:**
```json
{
  "webhook": {
    "scheme": "http",
    "host": "webhook.site",
    "port": 80,
    "method": "post",
    "path": "/your-webhook-endpoint",
    "headers": {
      "Content-Type": "application/json"
    }
  }
}
```

---

## üîß **Deploy e Configura√ß√£o**

### **Docker Compose** (`docker-compose.elk.yml`)

**Servi√ßos Configurados:**
- ‚úÖ Elasticsearch com health checks
- ‚úÖ Logstash com depend√™ncias
- ‚úÖ Kibana com configura√ß√µes
- ‚úÖ Filebeat com volumes
- ‚úÖ Metricbeat com m√©tricas
- ‚úÖ APM Server com endpoints

**Volumes Persistentes:**
- `elasticsearch_data` - Dados do Elasticsearch
- `filebeat_data` - Registry do Filebeat
- `metricbeat_data` - Registry do Metricbeat

### **Scripts de Deploy:**

#### **Linux/Mac** (`deploy-elk.sh`):
```bash
# Deploy completo
./deploy-elk.sh deploy

# Ver logs
./deploy-elk.sh logs

# Parar servi√ßos
./deploy-elk.sh stop

# Status dos servi√ßos
./deploy-elk.sh status
```

#### **Windows** (`deploy-elk.ps1`):
```powershell
# Deploy completo
.\deploy-elk.ps1 deploy

# Ver logs
.\deploy-elk.ps1 logs

# Parar servi√ßos
.\deploy-elk.ps1 stop

# Status dos servi√ßos
.\deploy-elk.ps1 status
```

---

## üìà **M√©tricas e Monitoramento**

### **M√©tricas Coletadas:**

#### **Sistema:**
- CPU usage
- Memory usage
- Disk I/O
- Network I/O
- Process metrics

#### **Aplica√ß√£o:**
- Response times
- Error rates
- Request counts
- User sessions
- Performance metrics

#### **Infraestrutura:**
- Container health
- Service availability
- Resource utilization
- Network connectivity

### **Dashboards Dispon√≠veis:**
- **System Overview** - M√©tricas do sistema
- **Application Performance** - Performance da aplica√ß√£o
- **Infrastructure Health** - Sa√∫de da infraestrutura
- **Security Monitoring** - Monitoramento de seguran√ßa
- **Custom Dashboards** - Dashboards personalizados

---

## üîç **Logs e Parsing**

### **Formatos de Log Suportados:**

#### **Application Logs:**
```
2025-09-02T19:30:00.000Z [INFO] app.routers.projects - Request GET /api/v1/projects/ - 200 - 150ms
```

#### **Nginx Logs:**
```
192.168.1.100 - - [02/Sep/2025:19:30:00 +0000] "GET /api/v1/health HTTP/1.1" 200 45 "-" "curl/7.68.0"
```

#### **PostgreSQL Logs:**
```
2025-09-02 19:30:00.000 UTC [1] LOG: database system is ready to accept connections
```

#### **Redis Logs:**
```
1:M 02 Sep 19:30:00.000 * Ready to accept connections
```

### **Parsing Patterns:**
- ‚úÖ ISO8601 timestamps
- ‚úÖ Log levels (INFO, WARN, ERROR)
- ‚úÖ HTTP requests
- ‚úÖ Database queries
- ‚úÖ Container logs

---

## üöÄ **Integra√ß√£o com Aplica√ß√£o**

### **Logging Estruturado:**

#### **Backend (FastAPI):**
```python
import structlog

logger = structlog.get_logger()

# Log estruturado
logger.info(
    "Request processed",
    method="GET",
    path="/api/v1/projects/",
    status_code=200,
    response_time=150,
    user_id="123"
)
```

#### **Frontend (React):**
```javascript
import { logger } from './utils/logger';

// Log estruturado
logger.info('User action', {
  action: 'project_created',
  project_id: '456',
  user_id: '123',
  timestamp: new Date().toISOString()
});
```

### **APM Integration:**
- ‚úÖ Transaction tracking
- ‚úÖ Error tracking
- ‚úÖ Performance monitoring
- ‚úÖ Custom metrics

---

## üìö **Comandos √öteis**

### **Elasticsearch:**
```bash
# Health check
curl http://localhost:9200/_cluster/health

# List indices
curl http://localhost:9200/_cat/indices

# Search logs
curl -X GET "localhost:9200/pm-ai-logs-*/_search" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "level": "ERROR"
    }
  }
}'
```

### **Kibana:**
```bash
# API status
curl http://localhost:5601/api/status

# List dashboards
curl http://localhost:5601/api/saved_objects/_find?type=dashboard
```

### **Logstash:**
```bash
# Pipeline status
curl http://localhost:9600/_node/stats

# Pipeline info
curl http://localhost:9600/_node/pipelines
```

---

## üîí **Seguran√ßa**

### **Configura√ß√µes de Seguran√ßa:**
- ‚úÖ SSL/TLS desabilitado (desenvolvimento)
- ‚úÖ Autentica√ß√£o desabilitada (desenvolvimento)
- ‚úÖ Network isolation via Docker
- ‚úÖ Volume permissions configuradas

### **Para Produ√ß√£o:**
- [ ] Habilitar SSL/TLS
- [ ] Configurar autentica√ß√£o
- [ ] Implementar RBAC
- [ ] Configurar firewall
- [ ] Backup autom√°tico

---

## üö® **Troubleshooting**

### **Problemas Comuns:**

#### **1. Elasticsearch n√£o inicia:**
```bash
# Verificar logs
docker-compose -f docker-compose.elk.yml logs elasticsearch

# Verificar mem√≥ria
docker stats

# Verificar permiss√µes
ls -la logging/elasticsearch/
```

#### **2. Logstash n√£o processa logs:**
```bash
# Verificar pipeline
curl http://localhost:9600/_node/pipelines

# Verificar configura√ß√£o
docker-compose -f docker-compose.elk.yml exec logstash cat /usr/share/logstash/config/logstash.yml
```

#### **3. Kibana n√£o carrega:**
```bash
# Verificar status
curl http://localhost:5601/api/status

# Verificar conex√£o com Elasticsearch
curl http://localhost:9200/_cluster/health
```

#### **4. Filebeat n√£o envia logs:**
```bash
# Verificar status
docker-compose -f docker-compose.elk.yml logs filebeat

# Verificar registry
docker-compose -f docker-compose.elk.yml exec filebeat filebeat test config
```

---

## üìä **Performance e Otimiza√ß√£o**

### **Configura√ß√µes de Performance:**

#### **Elasticsearch:**
- Heap size: 2GB
- Index buffer: 20%
- Query cache: 10%
- Circuit breakers configurados

#### **Logstash:**
- Workers: 2
- Batch size: 1000
- Queue persistida
- Dead letter queue

#### **Kibana:**
- Heap size: 1GB
- Bundle cache habilitado
- Optimize habilitado

### **Monitoramento de Performance:**
- ‚úÖ CPU usage
- ‚úÖ Memory usage
- ‚úÖ Disk I/O
- ‚úÖ Network I/O
- ‚úÖ Query performance
- ‚úÖ Index performance

---

## üéØ **Pr√≥ximos Passos**

### **Melhorias Futuras:**
1. **Security Hardening**
   - [ ] SSL/TLS em produ√ß√£o
   - [ ] Autentica√ß√£o e autoriza√ß√£o
   - [ ] RBAC implementation

2. **Advanced Analytics**
   - [ ] Machine Learning jobs
   - [ ] Anomaly detection
   - [ ] Predictive analytics

3. **Integration**
   - [ ] Prometheus metrics
   - [ ] Grafana dashboards
   - [ ] Slack notifications

4. **Backup & Recovery**
   - [ ] Automated backups
   - [ ] Disaster recovery
   - [ ] Data retention policies

---

## üéâ **Conclus√£o**

A **Fase 3: Monitoring & Logging** foi conclu√≠da com sucesso! O sistema agora possui:

- ‚úÖ **ELK Stack completo** implementado
- ‚úÖ **Logging estruturado** de todos os servi√ßos
- ‚úÖ **Dashboards avan√ßados** no Kibana
- ‚úÖ **Sistema de alertas** com Watcher
- ‚úÖ **M√©tricas em tempo real** via Metricbeat
- ‚úÖ **APM** para monitoramento de aplica√ß√£o
- ‚úÖ **Scripts de deploy** para Linux e Windows
- ‚úÖ **Documenta√ß√£o completa** e troubleshooting

**O sistema est√° pronto para monitoramento em produ√ß√£o com visibilidade completa!**

---

*√öltima atualiza√ß√£o: 2 de Setembro de 2025*  
*Respons√°vel: Equipe de Desenvolvimento PM AI MVP*
